{"cells":[{"cell_type":"markdown","metadata":{"id":"LRqt_7qdztLm"},"source":["textual inversion"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":921,"status":"ok","timestamp":1723211787242,"user":{"displayName":"xin yang","userId":"04446946633717040125"},"user_tz":-60},"id":"JJFaEDYrz_lD","outputId":"8a88b0f8-9114-4814-d2fb-4d90c6af6a72"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/diffusers\n"]}],"source":["%cd /content/drive/MyDrive/diffusers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vqmDfw-h0H9O"},"outputs":[],"source":["!pip install ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jksx6wze0tQV"},"outputs":[],"source":["from diffusers import StableDiffusionPipeline\n","import torch\n","\n","model_id = \"/content/drive/MyDrive/stable-diffusion-v1-4\"\n","pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16, use_safetensors=True).to(\"cuda\")\n","pipe.load_textual_inversion(\"/content/drive/MyDrive/shanshuifine\")\n","\n","prompt = \"a painting of mountains and rivers in <sks-style>\"\n","\n","\n","for i in range(100):\n","\n","    image = pipe(prompt, num_inference_steps=30, guidance_scale=7.5).images[0]\n","    save_path = f\"/content/drive/MyDrive/shanshui/textinversion11_{i+1}.png\"\n","    image.save(save_path)\n","    print(f\"Image {i+1} saved to {save_path}\")"]},{"cell_type":"markdown","metadata":{"id":"Am90TeC31cPr"},"source":["dreambooth lora\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j301yEIz5hoR"},"outputs":[],"source":["!pip install  -U PEFT  transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dD2KT4LR1gsY"},"outputs":[],"source":["from diffusers import StableDiffusionPipeline\n","import torch\n","\n","\n","pipe = StableDiffusionPipeline.from_pretrained(\"/content/drive/MyDrive/stable-diffusion-v1-4\", torch_dtype=torch.float16).to(\"cuda\")\n","pipe.unet.load_attn_procs(\"/content/drive/MyDrive/dreamfine/pytorch_lora_weights.safetensors\")\n","\n","\n","\n","for i in range(100):\n","    image = pipe(\"a painting of mountains and rivers in sks style\", num_inference_steps=30).images[0]\n","    save_path = f\"/content/drive/MyDrive/shanshui/dreamlora11_{i+1}.png\"\n","    image.save(save_path)\n","    print(f\"Image {i+1} saved to {save_path}\")"]},{"cell_type":"markdown","metadata":{"id":"f07MNgOX_eeM"},"source":["dreambooth\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J2Gd8u5j2BMR"},"outputs":[],"source":["from diffusers import StableDiffusionPipeline\n","import torch\n","\n","\n","model_id = \"/content/drive/MyDrive/dreamfine2\"\n","pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n","\n","prompt = \"a painting of mountains and rivers in sks style\"\n","\n","\n","for i in range(100):\n","\n","    image = pipe(prompt, num_inference_steps=30, guidance_scale=7.5).images[0]\n","    save_path = f\"/content/drive/MyDrive/shanshui/dream11_{i+1}.png\"\n","    image.save(save_path)\n","    print(f\"Image {i+1} saved to {save_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":866,"output_embedded_package_id":"1N_HaR8_yZnJblLoJwm0L9uMLWiPa1-UV"},"executionInfo":{"elapsed":16731,"status":"ok","timestamp":1723214267548,"user":{"displayName":"xin yang","userId":"04446946633717040125"},"user_tz":-60},"id":"kbe4qtx4jWEN","outputId":"c7893340-ea2f-4fb9-cb9b-b61191ffccb5"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["import os\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","folder_path = '/content/drive/MyDrive/shanshui'\n","\n","image_files = [f for f in os.listdir(folder_path) if f.endswith(('jpg', 'jpeg', 'png', 'gif', 'bmp'))]\n","\n","rows, cols = 3, 5\n","\n","fig, axes = plt.subplots(rows, cols, figsize=(15, 9))\n","\n","for i, ax in enumerate(axes.flat):\n","    if i < len(image_files):\n","        img_path = os.path.join(folder_path, image_files[i])\n","        img = Image.open(img_path)\n","        ax.imshow(img)\n","        ax.set_title(os.path.basename(image_files[i]), fontsize=8)\n","    ax.axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Qj5Ca16l_Avj"},"source":["CLIP score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":444,"status":"ok","timestamp":1721577316596,"user":{"displayName":"xin yang","userId":"04446946633717040125"},"user_tz":-60},"id":"CkkIDCh_AOLZ","outputId":"3d8220c6-e631-4bd7-c6ac-a039299b305b"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive\n"]}],"source":["%cd /content/drive/MyDrive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q1QUZKaA_aR7"},"outputs":[],"source":["!pip install git+https://github.com/openai/CLIP.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6098,"status":"ok","timestamp":1723223694449,"user":{"displayName":"xin yang","userId":"04446946633717040125"},"user_tz":-60},"id":"k9PiT7cj-0eC","outputId":"4d5cd42b-f197-413f-cd6a-c0440d6ba8b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Textual inversion Inception Score: 2.573744773864746\n","Dreambooth Inception Score: 2.3677496910095215\n","Dreamboothlora Inception Score: 2.633596897125244\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","from torchvision import models, transforms\n","from PIL import Image\n","import os\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","inception_model = models.inception_v3(pretrained=True, transform_input=False)\n","inception_model.eval()\n","inception_model.to(device)\n","\n","\n","transform = transforms.Compose([\n","    transforms.Resize((299, 299)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","def load_images_from_folder(folder):\n","    images = []\n","    for filename in os.listdir(folder):\n","        img = Image.open(os.path.join(folder, filename)).convert('RGB')\n","        if img is not None:\n","            img = transform(img)\n","            images.append(img.unsqueeze(0))\n","    return images\n","\n","def is_score(imgs, inception_model):\n","    with torch.no_grad():\n","        imgs = torch.cat(imgs, 0).to(device)\n","        outputs = inception_model(imgs)\n","    p_yx = F.softmax(outputs, dim=1)\n","    p_y = p_yx.mean(0).unsqueeze(0)\n","    kl = p_yx * (torch.log(p_yx) - torch.log(p_y))\n","    kl = kl.sum(1).mean()\n","    return torch.exp(kl).item()\n","\n","\n","folder_path = '/content/drive/MyDrive/textdata'\n","folder_path1 = '/content/drive/MyDrive/shanshui'\n","folder_path2 = '/content/drive/MyDrive/dreamwloradata'\n","\n","imgs = load_images_from_folder(folder_path)\n","score = is_score(imgs, inception_model)\n","imgs1 = load_images_from_folder(folder_path1)\n","score1 = is_score(imgs1, inception_model)\n","imgs2 = load_images_from_folder(folder_path2)\n","score2 = is_score(imgs2, inception_model)\n","print(f\"Textual inversion Inception Score: {score}\")\n","print(f\"Dreambooth Inception Score: {score1}\")\n","print(f\"Dreamboothlora Inception Score: {score2}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4404,"status":"ok","timestamp":1723225201786,"user":{"displayName":"xin yang","userId":"04446946633717040125"},"user_tz":-60},"id":"OUVs13fEFQb1","outputId":"a2062998-2ea3-4ece-ebd2-389964986e2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Label probs: [[0.4648 0.535 ]]\n"]}],"source":["import torch\n","import clip\n","from PIL import Image\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model, preprocess = clip.load(\"ViT-B/32\", device=device)\n","\n","image = preprocess(Image.open(\"/content/drive/MyDrive/Transfer/result/face2.jpg/face2单张原模型cartoon.jpg\")).unsqueeze(0).to(device)\n","text = clip.tokenize([\"a man\",'a man in cartoon style']).to(device)\n","\n","with torch.no_grad():\n","    image_features = model.encode_image(image)\n","    text_features = model.encode_text(text)\n","\n","    logits_per_image, logits_per_text = model(image, text)\n","    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n","\n","print(\"Label probs:\", probs)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4458,"status":"ok","timestamp":1723225183988,"user":{"displayName":"xin yang","userId":"04446946633717040125"},"user_tz":-60},"id":"Xdubvz17OMdv","outputId":"d04caf0b-f1af-4827-b703-aa70978b135c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Label probs: [[0.01133 0.989  ]]\n"]}],"source":["import torch\n","import clip\n","from PIL import Image\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model, preprocess = clip.load(\"ViT-B/32\", device=device)\n","\n","image = preprocess(Image.open(\"/content/drive/MyDrive/Transfer/result/face2.jpg/face2微调模型单张cartoon.jpg\")).unsqueeze(0).to(device)\n","text = clip.tokenize([\"a man\",'a man in cartoon style']).to(device)\n","\n","with torch.no_grad():\n","    image_features = model.encode_image(image)\n","    text_features = model.encode_text(text)\n","\n","    logits_per_image, logits_per_text = model(image, text)\n","    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n","\n","print(\"Label probs:\", probs)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4717,"status":"ok","timestamp":1723395215713,"user":{"displayName":"xin yang","userId":"04446946633717040125"},"user_tz":-60},"id":"4XPEOUm9McLE","outputId":"679ec5fc-eb60-4d78-c24d-6294d3259899"},"outputs":[{"name":"stdout","output_type":"stream","text":["Label probs: [[0.5 0.5]]\n"]}],"source":["import torch\n","import clip\n","from PIL import Image\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model, preprocess = clip.load(\"ViT-B/32\", device=device)\n","\n","image = preprocess(Image.open(\"/content/drive/MyDrive/Transfer/result/building2.jpg/building2原模型单张cartoon.jpg\")).unsqueeze(0).to(device)\n","text = clip.tokenize([\"a white builiding\",'a white building in cartoon style']).to(device)\n","\n","with torch.no_grad():\n","    image_features = model.encode_image(image)\n","    text_features = model.encode_text(text)\n","\n","    logits_per_image, logits_per_text = model(image, text)\n","    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n","\n","print(\"Label probs:\", probs)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5872,"status":"ok","timestamp":1723395205571,"user":{"displayName":"xin yang","userId":"04446946633717040125"},"user_tz":-60},"id":"kmEW1vSXWhg4","outputId":"7ae6b5ac-6eda-4ab3-9a52-69646432f2ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["Label probs: [[0.4688 0.5312]]\n"]}],"source":["import torch\n","import clip\n","from PIL import Image\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model, preprocess = clip.load(\"ViT-B/32\", device=device)\n","\n","image = preprocess(Image.open(\"/content/drive/MyDrive/Transfer/result/building2.jpg/building调模型单张cartoon.jpg\")).unsqueeze(0).to(device)\n","text = clip.tokenize([\"a white builiding\",'a white building in cartoon style']).to(device)\n","\n","with torch.no_grad():\n","    image_features = model.encode_image(image)\n","    text_features = model.encode_text(text)\n","\n","    logits_per_image, logits_per_text = model(image, text)\n","    probs = logits_per_image.softmax(dim=-1).cpu().numpy()\n","\n","print(\"Label probs:\", probs)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMllIrbaIbK2G0EReEDadZk","gpuType":"A100","machine_shape":"hm","mount_file_id":"1Pj6tOlSbOgdjmyfLYNOJd1_QjzCEPddd","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
